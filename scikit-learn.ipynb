{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/softwareengineeringdaily.com/wp-content/uploads/2016/09/scikit-learn-logo.png?resize=566%2C202&ssl=1\" alt=\"image info\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author: John Paul Lee\n",
    "* Github: JPLee01\n",
    "* Email: G00387906@gmit.ie\n",
    "* Created: 04-11-2021, Last update: XX-12-2021\n",
    "* Machine Learning and Statistics: Investigation into the Scikit-learn and Scipy-Stats Python libraries.\n",
    "***\n",
    "* This Jupyter Notebook has been created to investigate the Scikit-learn Python library by offeing an overview, demonstration, plots and visualisations of each of the libraries.\n",
    "\n",
    "**Lecturer:** Dr. Ian McLoughlin\n",
    "\n",
    "The Project instructions can be found [here](https://github.com/JPLee01/Machine_Learning_and_Statistics/blob/main/Instructions.pdf)\n",
    "***\n",
    "As part of the project this notebook will deal with three main tasks:\n",
    "\n",
    "1. Offer an overview of the Scikit-learn and Scipy-Stats Python libraries.\n",
    "2. Demonstrate three Scikit-learn algorithms and a Scipy-Stats hypothsis test using ANOVA.\n",
    "3. Create plots and visualisations as necessary.\n",
    "\n",
    "## Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to dealing with each section we first need to import a number of libraries. We need to import the Scikit-learn  library to allow for a comprehensive explanation of the library and machine learning to take place. The NumPy library is imported to allow for synthesisation of data sets. The Pandas library will also be imported to allow for analysis of the data sets. Finally the Matplotlib and Seaborn libraries will also need to be imported to allow for the creation of visualisations in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Scikit-learn to allow for machine learning to take place\n",
    "import sklearn\n",
    "\n",
    "#Import Pandas for Data Management \n",
    "import pandas as pd\n",
    "\n",
    "#Import Numpty for Analysis of the data \n",
    "import numpy as np\n",
    "\n",
    "#Import matplotlib.pyplot and seaborn for Visualisation of the data \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also as we will be displaying Plots in this Jupyter Notebook we will implement the inline magic command to allow the Plots to be rendered inline within the Notebook.<sup>[1]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inline Magic command implemented to ensure that the Plots are rendered inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure uniformity throughout the Juypter Notebook in terms of the the Seaborn Plots display the style and palette fuction will be set.\n",
    "\n",
    "The style function will be set to darkgrid. This will allow for optimal measurements of Plots as the darkened background with the built in grid lines will be best displayed against the white background of the Juypter Notebook.<sup>[2]</sup>\n",
    "\n",
    "The palette fuction will be set to bright as it will allow for clear distinction of multiple outputs within one Plot.<sup>[3]</sup>\n",
    "\n",
    "Finally in order to ensure uniformity throughout the notebook the plots size will be set using the rcParams function.<sup>[4]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting of Seaborn dispays to enure uniformity throughout the Juypter Notebook\n",
    "#Darkplot style selected to allow for optimal measurments of Plots\n",
    "sns.set_style(\"darkgrid\")\n",
    "#Bright colour palette selected to allow for clear distinction of multiple outputs within one Plot \n",
    "sns.set_palette(\"bright\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot style\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Increase the size of the output plots\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scikit-Learn\n",
    "\n",
    "The scikit-learn is a machine learning library for the Python programming language.<sup>[5]</sup> Initially developed as a Google summer of code project by David Cournapeau in 2007, scikit-learn is now one of the most popular machine learning libraries on GitHub.<sup>[6]</sup> Built on NumPy, SciPy and matplotlib libraries, scikit-learn is considered the gold standard for Machine Learning in the Python ecosystem.<sup>[7]</sup> Scikit-learn's key concepts and features include:<sup>[8]</sup>\n",
    "* Algorithmic decision-making methods, including:\n",
    "    * **Classification:** identifying and categorizing data based on patterns.\n",
    "    * **Regression:** predicting or projecting data values based on the average mean of existing and planned data.\n",
    "    * **Clustering:** automatic grouping of similar data into datasets.\n",
    "* Algorithms that support predictive analysis ranging from simple linear regression to neural network pattern recognition.\n",
    "* Interoperability with NumPy, pandas, and matplotlib libraries.\n",
    "\n",
    "Scikit-learn aims to provide a range of supervised and unsupervised learning algorithms to the user.<sup>[9]</sup>\n",
    "* **Supervised Learning Algorithms** refer to algorithms which attempts to model relationships and dependencies between the target prediction output and the input features.<sup>[10]</sup> Within supervised learning algorithms the input variables (*x*) and an output variable (*Y*) are know and the algorithm is employed learn the mapping function from the input to the output. The goal of supervised learning algorithmsis are to approximate the mapping function so well that when you have new input data (*x*) that you can predict the output variables (*Y*) for that data.<sup>[11]</sup> As the name suggests supervised learning algorithms incorporate the use of a \"supervisor or a teacher\". The supervisor is labeled training data which teaches the constructed algorithm to detect the underlying patterns and relationships between the input data and the output labels.<sup>[12]</sup> This algorithm is refined until it is able to yield accurate labeling results when presented with never-before-seen data.<sup>[13]</sup> This is concept similiar to the way a student learns in the supervision of a teacher.<sup>[14]</sup> Some of the advantages of supervised learning algorithms is that they offer the user a high degree of control of the training process and the definition of the classes<sup>[15]</sup> While some of the disadvantages are it's not seen as the most efficient option for dealing with complex tasks and can be very time intensive.<sup>[16]</sup>\n",
    "\n",
    "* **Unsupervised Learning Algorithms** are a type of machine learning algorithms in which no pre-assigned labels or scores are provided to the training data.<sup>[17]</sup> As a result these algorithms discover hidden patterns or data groupings without the need for human intervention (hence the name unsupervised).<sup>[18]</sup> While the goal of supervised learning is to predict outcomes for new data. The goal of unsupervised learning is to get insights from large volumes of new data. The algorithm itself determines what is different or interesting from the dataset.<sup>[19]</sup> Due to its ability to discover similarities and differences in data, unsupervised learning algorithms are widely used in the fields of exploratory data analysis and image recognition.<sup>[20]</sup> Some of the advantages of unsupervised learning algorithms are that they can uncover hidden patterns which the user might not have previously considered, and the  opportunity for human error is drastically minimized.<sup>[21]</sup> While some of the disadvantages include questions over the accuracy of the results due to the lack input data to train from, and no guarantee that the obtained results will be of benefit to the user.<sup>[22]</sup>\n",
    "\n",
    "    The processes for both supervised and unsupervised learning algorithms can be seen in the images below:<sup>[23]</sup>\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained1.png\" alt=\"Supervised\" style=\"width: 450px; height: 450px;\"/> </td>\n",
    "<td> <img src=\"https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained2.png\" alt=\"Unsupervised\" style=\"width: 450px; height: 450px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "<img src=\"https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained1.png\" alt=\"Supervised\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained2.png\" alt=\"Unsupervised\"/>\n",
    "\n",
    "Scikit-learn has six main areas in which it can be applied:<sup>[24]</sup>\n",
    "1. **Supervised Learning Algorithms** − Including; Linear Regression, Support Vector Machines, Nearest neighbors and Decision Trees.<sup>[25]</sup>\n",
    "2. **Unsupervised Learning Algorithms** − Including; Gaussian Mixture Models, Clustering, Covariance Estimation and Density Estimation.<sup>[26]</sup> \n",
    "3. **Model Selection and Evaluation** − Selection of the right model to allow for evaluation of the dataset such as Cross-validation and Validation Curves.<sup>[27]</sup> \n",
    "4. **Inspection** - Inspection of the performance of algorithms through the use of Partial Dependence and Individual Conditional Expectation plots as well as the Permutation Feature Importance module.<sup>[28]</sup> \n",
    "5. **Visualisations** - Application Programming Interface (API) for Visualisation generation.<sup>[29]</sup> \n",
    "6. **Dataset Transformations** - Library of transformers which may clean, reduce, expand or generate feature representations.<sup>[30]</sup>\n",
    "\n",
    "Due to its permissive simplified BSD license, scikit-learn is also widely used in both academic and commercial circles including; JP Morgan, Spotify, Booking.com etc. <sup>[31]</sup><sup>[32]</sup> \n",
    "\n",
    "Scikit-learn has also a number of embedded datasets which do not require to download any file from some external website.<sup>[33]</sup> These include both toy (fictional) and real world datasets.<sup>[34]</sup><sup>[35]</sup> The author will call on these datasets for different sections of the assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scikit-Learn Algorithms\n",
    "For this section of the assessment the author will conduct a detailed analysis of three different scikit-learn algorithms. The author will provide an overview of the algorithms, implement them on a dataset and discuss the results as well as provide visualisations. The author will also compare and contrast the different algorithms in terms of **accuracy, ease of use and relevance**. (REWORD)\n",
    "\n",
    "**In order to best examine the analogy between the different algorithms the same dataset will be used thorughout. As previously discussed, scikit-learn has a number of embedded datasets. The author will call on the embedded Iris dataset for this section of the assessment.** (REWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Iris Dataset Oview\n",
    "The data analysed in this project is the \\\"Iris Flower Data Set\\\".<sup>[36]</sup> This data set was collected by R.A. Fisher and presented as a data set in 1936 in his paper \\\"The Use of Multiple Measurements in Taxonomic Problems\\\".<sup>[37]</sup> In this paper Fisher studied the use of linear combinations of multiple characterising features of a species to discriminate it from related species. Within the paper Fisher studied the following three related species of Iris flowers; Setosa, Versicolor and Virginica. These can be seen visually below:\n",
    "\n",
    "![Iris Species](https://miro.medium.com/max/1400/0*Uw37vrrKzeEWahdB)\n",
    "\n",
    "Fifty samples of each species were collected and analysed. (It should be noted that the data for the Setosa and Versicolor were already available from a previous study by Fisher's colleague Botanist Edgar Anderson). Within each species, Fisher studied four distinct characteristics:\n",
    "\n",
    "1.  Sepal Length (Cm)\n",
    "2.  Sepal Width (Cm)\n",
    "3.  Petal Length (Cm)\n",
    "4.  Petal Width (Cm)\n",
    "\n",
    "These characteristics can be seen below:\n",
    "\n",
    "  ![Iris Characteristics](https://miro.medium.com/max/800/1*1q79O5DCx_XNrAARXSFzpg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Loading the Data Set\n",
    "Due to the presence of the Iris Data Set within the Scikit-learn Library the author will use the import function to load the data set directly form the Scikit-learn Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation of the Iris Data Set directly from the Scikit-learn Library\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Loading of the Iris Data Set\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Creation of a DataFrame \n",
    "In order of allow for ease of use in terms of analysis the author will create a DataFrame of the Data Set using the Pandas DataFrame function.<sup>[38]</sup> The author used the Numpy concatenate function to create the DataFrame.<sup>[39]</sup> The below code is inpired from a Stack Overflow question on the topic.<sup>[40]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a DataFrame of the Iris Data Set for ease of use\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Creation of a Species DataFrame \n",
    "In order for further analysis of the Data Set to take place the author created a Species specific DataFrame. The was achieved using the Pandas Categorical.from_codes function<sup>[41]</sup>, and was also inspire from the perviously mentioned Stack Overflow question.<sup>[40]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Species present in this dataset are:\n",
      "> setosa\n",
      "> versicolor\n",
      "> virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creation of a Species DataFrame\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "#Print the List of the Species in the Data Set\n",
    "Specieslist = df[\"species\"].unique()\n",
    "print (\"The Species present in this Data Set are:\")\n",
    "for i in Specieslist:\n",
    "    print('>', i)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results the DataFrame has three species present; Setosa, Versicolor and Virginica. This is in line with previously reported information on the Data Set.<sup>[42]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Overview of the Iris DataFrame\n",
    "In order to conifrm the legitimacy of the created Iris DataFrame the author will print the amount of samples of each species and the summary statistics for all the species (Rounded to three decimal places). This code was created using the Pandas.DataFrame.value_counts<sup>[43]</sup>, Pandas.DataFrame.describe<sup>[44]</sup> and Pandas.Round command.<sup>[45]</sup> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of samples of each Species:\n",
      "virginica     50\n",
      "versicolor    50\n",
      "setosa        50\n",
      "Name: species, dtype: int64 \n",
      "\n",
      "Summary Statistics of all the Species (Rounded to 3 Decimal Places):\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count            150.000           150.000            150.000   \n",
      "mean               5.843             3.057              3.758   \n",
      "std                0.828             0.436              1.765   \n",
      "min                4.300             2.000              1.000   \n",
      "25%                5.100             2.800              1.600   \n",
      "50%                5.800             3.000              4.350   \n",
      "75%                6.400             3.300              5.100   \n",
      "max                7.900             4.400              6.900   \n",
      "\n",
      "       petal width (cm)   target  \n",
      "count           150.000  150.000  \n",
      "mean              1.199    1.000  \n",
      "std               0.762    0.819  \n",
      "min               0.100    0.000  \n",
      "25%               0.300    0.000  \n",
      "50%               1.300    1.000  \n",
      "75%               1.800    2.000  \n",
      "max               2.500    2.000   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the Amount of Samples of each Species in the Data Set\n",
    "print(\"Amount of samples of each Species:\")\n",
    "print(df['species'].value_counts(), '\\n')\n",
    "\n",
    "#Print the Summary Statistics for all the Species (Rounded to 3 Decimal Places)\n",
    "print(\"Summary Statistics of all the Species (Rounded to 3 Decimal Places):\")\n",
    "print(round(df.describe(),3),'\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above we can see that each species has fifty samples and each measurment has one hundred and fifty samples. This is in line with pervious summary statistics of the Iris Data Set.<sup>[46]</sup> \n",
    "\n",
    "Now that a legitimate Iris DataFrame has been created the author will now focus of the analysis of this DataFrame using three different Scikit-learn algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Support Vector Machine\n",
    "A support vector machine (SVM) is a supervised machine learning model that is used for classification, regression and outliers detection.<sup>[47]</sup> SVM uses classification algorithms that find a hyperplane (a subspace whose dimension is one less than that of its ambient space<sup>[48]</sup>) that best divides a dataset into two classes.<sup>[49]</sup> The aim of SVM is to plot each data item as a point in *n*-dimensional space (where *n* is a number of features you have) with the value of each feature being the value of a particular coordinate. Then classification is performed by finding the hyper-plane that most effectively differentiates the two classes.<sup>[50]</sup> \n",
    "\n",
    "SVM can be best explained in the following example. In a data set you need to classify the red rectangles from the blue ellipses. As a result you need to identify the most efficient line (hyperplane) that separates this dataset into two classes i.e red and blue. \n",
    "\n",
    "![SMV Example 1](https://miro.medium.com/max/1280/1*VDATmWG1E1ZNg7hdasOh5g.png)\n",
    "\n",
    "As can be seen from the below image there are a multitude of lines that can be constructed to separates the dataset, with varring degrees of efficiency. \n",
    "\n",
    "![SMV Example 2](https://miro.medium.com/max/1280/1*AMR3v-jCvUMXPUtQskzxmQ.png)\n",
    "\n",
    "SVM finds the most efficient line by identifying the closest points from both classes to the line. These points are called support vectors. Now, we compute the distance between the line and the support vectors. This distance is called the margin. Our goal is to maximize the margin. The line that maximizes the margin between the two classes is the optimal hyperplane (line).\n",
    "\n",
    "![SMV Example 3](https://miro.medium.com/max/1280/1*irg_jfdAar9gfe0j-Q04vQ.png)\n",
    "\n",
    "When a data set cannot by linearly (straight line) separable it is converted to linearly separable data in higher dimension. This is achieved through the additon of an extra dimension called the *z-axis* and let the co-ordinates be governed by the constraint *z = x²+y²*. This is to say the *z* co-ordinate is the square of distance of the point from origin.\n",
    "\n",
    "![SMV Example 4](https://miro.medium.com/max/1280/1*a_TQSZ_H1UOA3BV299qtJQ.png)\n",
    "\n",
    "As a result the data is clearly linearly separable. Now we will add a purple line separating data in higher dimension and let it be *z=k*, where *k* is a constant. Since, *z=x²+y²* we get *x²+y²=k*; which is an equation of a circle. As a result, we can project this linear separator in higher dimension back in original dimensions using this transformation.\n",
    "\n",
    "![SMV Example 5](https://miro.medium.com/max/1280/1*WTg1NgtzaoUoQP7N5HucSA.png)\n",
    "\n",
    "\n",
    "This can be also be show graphically in the below 3D image:\n",
    "\n",
    "![SMV Example 6](https://fan-gong.github.io/posts/SVM/3.jpg)\n",
    "\n",
    "The addition of this extra *z-axis* dimension is also referred to as the kernel trick and it extreemely useful in situation when you are dealing with a non-linear separation problem.<sup>[51]</sup> \n",
    "\n",
    "There are a number of advantages of using the SVM algorithm including; effectiveness in high dimensional data, it ability to solve  both regression and classification problems and its effectiveness in cases where number of dimensions is greater than the number of samples.<sup>[52]</sup> While its disadvantages include; inefficiency when dealing with noisey data sets i.e. overlapping classes, time taken to train large data sets and it inability to directly provide probability estimates.<sup>[53]</sup>\n",
    "\n",
    "The author will now demonstrate the use of the SVM algorithm on the Iris Data Set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TALK ABOUT TRAIN/TEST OF DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"myfootnote1\">1</a>: Stack Overflow - Purpose of “%matplotlib inline”, https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline/43028034\n",
    "\n",
    "<a name=\"myfootnote2\">2</a>: The Python Graph Gallery - 104 Seaborn Themes, https://python-graph-gallery.com/104-seaborn-themes/\n",
    "\n",
    "<a name=\"myfootnote3\">3</a>: Seaborn - Choosing color palettes, https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "\n",
    "<a name=\"myfootnote4\">4</a>: Mathplotlib - Customizing Matplotlib with style sheets and rcParams, https://matplotlib.org/stable/tutorials/introductory/customizing.html\n",
    "\n",
    "<a name=\"myfootnote5\">5</a>: Fabian Pedregosa et al. - Scikit-learn: Machine Learning in Python, https://jmlr.org/papers/v12/pedregosa11a.html\n",
    "\n",
    "<a name=\"myfootnote6\">6</a>: Thomas Elliott - The State of the Octoverse: machine learning, https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/\n",
    "\n",
    "<a name=\"myfootnote7\">7</a>: George Seif - An Introduction to Scikit Learn: The Gold Standard of Python Machine Learning, https://www.kdnuggets.com/2019/02/introduction-scikit-learn-gold-standard-python-machine-learning.html\n",
    "\n",
    "<a name=\"myfootnote8\">8</a>: Active State - What Is Scikit-Learn In Python?, https://www.activestate.com/resources/quick-reads/what-is-scikit-learn-in-python/\n",
    "\n",
    "<a name=\"myfootnote9\">9</a>: Jason Brownlee - A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library, https://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/\n",
    "\n",
    "<a name=\"myfootnote10\">10</a>: David Fumo - Types of Machine Learning Algorithms You Should Know, https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861\n",
    "\n",
    "<a name=\"myfootnote11\">11</a>: Jason Brownlee  - Supervised and Unsupervised Machine Learning Algorithms, https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/\n",
    "\n",
    "<a name=\"myfootnote12\">12</a>: Java Point - Supervised Machine Learning, https://www.javatpoint.com/supervised-machine-learning\n",
    "\n",
    "<a name=\"myfootnote13\">13</a>: David Petersson - Supervised Learning, https://searchenterpriseai.techtarget.com/definition/supervised-learning\n",
    "\n",
    "<a name=\"myfootnote14\">14</a>: Data Robot - Supervised Machine Learning, https://www.datarobot.com/wiki/supervised-machine-learning/\n",
    "\n",
    "<a name=\"myfootnote15\">15</a>: Pythonista Planet - Pros and Cons of Supervised Machine Learning, https://pythonistaplanet.com/pros-and-cons-of-supervised-machine-learning/\n",
    "\n",
    "<a name=\"myfootnote16\">16</a>: Ronald van Loon - Machine learning explained: Understanding supervised, unsupervised, and reinforcement learning, https://bigdata-madesimple.com/machine-learning-explained-understanding-supervised-unsupervised-and-reinforcement-learning/\n",
    "\n",
    "<a name=\"myfootnote17\">17</a>: Geoffrey Hinton - A Practical Guide to Training Restricted Boltzmann Machines, https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf\n",
    "\n",
    "<a name=\"myfootnote18\">18</a>: IBM - Unsupervised Learning, https://www.ibm.com/cloud/learn/unsupervised-learning\n",
    "\n",
    "<a name=\"myfootnote19\">19</a>: IBM - Supervised vs. Unsupervised Learning: What’s the Difference?, https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning\n",
    "\n",
    "<a name=\"myfootnote20\">20</a>: Java Point - Unsupervised Machine Learning, https://www.javatpoint.com/unsupervised-machine-learning\n",
    "\n",
    "<a name=\"myfootnote21\">21</a>: Asquero - Advantages and Disadvantages of different types of machine learning algorithms, https://www.asquero.com/article/advantages-and-disadvantages-of-different-types-of-machine-learning-algorithms/\n",
    "\n",
    "<a name=\"myfootnote22\">22</a>: Pythonista Planet - Pros and Cons of Unsupervised Learning, https://pythonistaplanet.com/pros-and-cons-of-unsupervised-learning/\n",
    "\n",
    "<a name=\"myfootnote23\">23</a>: Ronald van Loon - Machine learning explained: Understanding supervised, unsupervised, and reinforcement learning, https://bigdata-madesimple.com/machine-learning-explained-understanding-supervised-unsupervised-and-reinforcement-learning/\n",
    "\n",
    "<a name=\"myfootnote24\">24</a>: Scikit-learn - User Guide Overview, https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "<a name=\"myfootnote25\">25</a>:  Scikit-learn - User Guide: Chapter 1. Supervised learning, https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "<a name=\"myfootnote26\">26</a>: Scikit-learn - User Guide: Chapter 2. Unsupervised learning,https://scikit-learn.org/stable/unsupervised_learning.html\n",
    "\n",
    "<a name=\"myfootnote27\">27</a>: Scikit-learn - User Guide: Chapter 3. Model selection and evaluation, https://scikit-learn.org/stable/model_selection.html\n",
    "\n",
    "<a name=\"myfootnote28\">28</a>: Scikit-learn - User Guide: Chapter 4. Inspection, https://scikit-learn.org/stable/inspection.html\n",
    "\n",
    "<a name=\"myfootnote29\">29</a>: Scikit-learn - User Guide: Chapter 5. Visualizations, https://scikit-learn.org/stable/visualizations.html\n",
    "\n",
    "<a name=\"myfootnote30\">30</a>: Scikit-learn - User Guide: Chapter 6. \n",
    "\n",
    "<a name=\"myfootnote31\">31</a>: Dataquest - Scikit-learn Tutorial: Machine Learning in Python, https://www.dataquest.io/blog/sci-kit-learn-tutorial/\n",
    "\n",
    "<a name=\"myfootnote32\">32</a>: Scikit-learn - Who is using scikit-learn?, https://scikit-learn.org/stable/testimonials/testimonials.html\n",
    "\n",
    "<a name=\"myfootnote33\">33</a>: Scikit-learn - User Guide: Chapter 7. Dataset loading utilities, https://scikit-learn.org/stable/datasets.html\n",
    "\n",
    "<a name=\"myfootnote34\">34</a>: Scikit-learn - User Guide: Chapter 7.1 Toy Datasets, https://scikit-learn.org/stable/datasets/toy_dataset.html\n",
    "\n",
    "<a name=\"myfootnote35\">35</a>: Scikit-learn - User Guide: Chapter 7.2 Real World Datasets, https://scikit-learn.org/stable/datasets/real_world.html\n",
    "\n",
    "<a name=\"myfootnote36\">36</a>: UCI Machine Learning Repository - Iris Data Set, <http://archive.ics.uci.edu/ml/datasets/Iris>\n",
    "\n",
    "<a name=\"myfootnote37\">37</a>: The Use of Multiple Measurements in Taxonomic Problems, <http://www.comp.tmu.ac.jp/morbier/R/Fisher-1936-Ann._Eugen.pdf>\n",
    "\n",
    "<a name=\"myfootnote38\">38</a>: Pandas User Guide Version 1.3.4 - pandas.DataFrame Function, https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "\n",
    "<a name=\"myfootnote39\">39</a>: Numpy Manual Version 1.21 - numpy.concatenate Function, https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html\n",
    "\n",
    "<a name=\"myfootnote40\">40</a>: Stack Overflow - How to convert a Scikit-learn dataset to a Pandas dataset, https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset\n",
    "\n",
    "<a name=\"myfootnote41\">41</a>: Pandas User Guide Version 1.3.4 - pandas.Categorical.from_codes Function, https://pandas.pydata.org/docs/reference/api/pandas.Categorical.from_codes.html\n",
    "\n",
    "<a name=\"myfootnote42\">42</a>: Pranshu Sharma - Exploratory Data Analysis : Iris Dataset, https://medium.com/analytics-vidhya/exploratory-data-analysis-iris-dataset-4df6f045cda\n",
    "\n",
    "<a name=\"myfootnote43\">43</a>: Pandas User Guide Version 1.3.4 - pandas.DataFrame.value_counts Function, https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html\n",
    "\n",
    "<a name=\"myfootnote44\">44</a>: Pandas User Guide Version 1.3.4 - pandas.DataFrame.describe Function, https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "<a name=\"myfootnote45\">45</a>: Pandas User Guide Version 1.3.4 - pandas.DataFrame.round Function, https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.round.html\n",
    "\n",
    "<a name=\"myfootnote46\">46</a>: A Akshay - Descriptive Statistics with Pandas on iris data(beginner), https://akshay-a.medium.com/descriptive-statistics-with-pandas-on-iris-data-beginner-bbc4422597ea\n",
    "\n",
    "<a name=\"myfootnote47\">47</a>: Scikit-learn - User Guide: Chapter 1.4 Support Vector Machines, https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "<a name=\"myfootnote48\">48</a>: IGI Global - What is Hyperplane, https://www.igi-global.com/dictionary/machine-learning-for-industrial-iot-systems/34033\n",
    "\n",
    "<a name=\"myfootnote49\">49</a>: Sunil Ray - Understanding Support Vector Machine(SVM) algorithm from examples (along with code), https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n",
    "\n",
    "<a name=\"myfootnote50\">50</a>: Monkey Learn - Support Vector Machines (SVM) Algorithm Explained, https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/\n",
    "\n",
    "<a name=\"myfootnote51\">51</a>: Rohith Gandhi - Support Vector Machine — Introduction to Machine Learning Algorithms, https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47 \n",
    "\n",
    "<a name=\"myfootnote52\">52</a>: Bot Bark - Top 5 Advantages and Disadvantages of Support Vector Machine Algorithm, https://botbark.com/2019/12/19/top-5-advantages-and-disadvantages-of-support-vector-machine-algorithm/\n",
    "\n",
    "<a name=\"myfootnote53\">53</a>: Dhiraj K - Top 4 advantages and disadvantages of Support Vector Machine or SVM, https://dhirajkumarblog.medium.com/top-4-advantages-and-disadvantages-of-support-vector-machine-or-svm-a3c06a2b107\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the course of this assessment the following sources were also used for research purposes:\n",
    "* Baglom - 10 Scikit-Learn Case Studies, Examples and Tutorials, http://www.baglom.com/b/10-scikit-learn-case-studies-examples-tutorials-cm572/\n",
    "* Bogo to Bogo - Scikit-Learn : Unsupervised Learning - Clustering, https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Unsupervised_Learning_Clustering.php\n",
    "* Code Cademy - What is Scikit-Learn?, https://www.codecademy.com/articles/scikit-learn\n",
    "* Daniel Johnson - Supervised vs Unsupervised Learning: Key Differences, https://www.guru99.com/supervised-vs-unsupervised-learning.html\n",
    "* Daniel Johnson - Unsupervised Machine Learning: What is, Algorithms, Example, https://www.guru99.com/unsupervised-machine-learning.html\n",
    "* Data Robot - Unsupervised Machine Learning, https://www.datarobot.com/wiki/unsupervised-machine-learning/\n",
    "* Drew Wilimitis - The Kernel Trick in Support Vector Classification, https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f\n",
    "* Geeks for Geeks - Supervised and Unsupervised learning, https://www.geeksforgeeks.org/supervised-unsupervised-learning/\n",
    "* IBM - Markdown for Jupyter notebooks cheatsheet, https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet\n",
    "* IBM - Supervised Learning, https://www.ibm.com/cloud/learn/supervised-learning\n",
    "* Noel Bambrick - Support Vector Machines: A Simple Explanation, https://www.kdnuggets.com/2016/07/support-vector-machines-simple-explanation.html\n",
    "* OpenDataScience - The A – Z of Supervised Learning, Use Cases, and Disadvantages, https://opendatascience.com/the-a-z-of-supervised-learning-use-cases-and-disadvantages/\n",
    "* Quora - What are the advantages and disadvantages of a supervised learning machine?, https://www.quora.com/What-are-the-advantages-and-disadvantages-of-a-supervised-learning-machine\n",
    "* R. Berwick - An Idiot’s guide to Support vector machines (SVMs), http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf\n",
    "* Rushikesh Pupale - Support Vector Machines(SVM) — An Overview, https://towardsdatascience.com/https-medium-com-pupalerushikesh-svm-f4b42800e989\n",
    "* Sadrach Pierre - A Comprehensive Guide to Scikit-Learn (Sklearn), https://builtin.com/machine-learning/scikit-learn-guide\n",
    "* Sanatan Mishra - Unsupervised Learning and Data Clustering, https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a\n",
    "* Scikit-learn - User Guide: Frequntly Asked Questions, https://scikit-learn.org/stable/faq.html\n",
    "* Scikit-learn - Official Website, https://scikit-learn.org/stable/\n",
    "* Snehit Vaddi - Most used Scikit-Learn Algorithms Part-1|Snehit Vaddi, https://medium.com/analytics-vidhya/most-used-scikit-learn-algorithms-part-1-snehit-vaddi-7ec0c98e4edd\n",
    "* Snehit Vaddi - Most used Scikit-Learn Algorithms Part-2|Snehit Vaddi, https://medium.com/analytics-vidhya/most-used-scikit-learn-algorithms-part-1-snehit-vaddi-7ec0c98e4edd\n",
    "* Stack Overflow - Round each number in a Python Pandas data frame by 2 decimals, https://stackoverflow.com/questions/25272024/round-each-number-in-a-python-pandas-data-frame-by-2-decimals\n",
    "* Techopedia - Scikit-Learn, https://www.techopedia.com/definition/33860/scikit-learn\n",
    "* Tech Vidvan - Unsupervised Learning – Machine Learning Algorithms, https://techvidvan.com/tutorials/unsupervised-learning/\n",
    "* Visually Explained - Support Vector Machine (SVM) in 2 minutes, https://www.youtube.com/watch?v=_YPScrckx28\n",
    "* When Maths Meet Coding - Kernel Trick in Support Vector Machine (SVM) | explained with visualization, https://www.youtube.com/watch?v=wqSTBCguVyU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
